# -*- coding: utf-8 -*-
"""heart disease Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FZh3_mGn8RZxqBcT7GOGXaWomzOhM0F5
"""

import pandas as pd
import io
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
import joblib

df = pd.read_csv('heart.csv')

df.head()

df.head(10)

df.tail()

df.tail(10)

df.describe()

df['Age'].describe()

df.info()

df.columns

df.HeartDisease.value_counts()

sns.countplot(x='HeartDisease', data=df, palette='bwr')
plt.show()

#now lets count our target
countNoDisease = len(df[df.HeartDisease == 0])
countDisease = len(df[df.HeartDisease == 1])
print("Percentage of Patients Haven't Disease : {:2f} %".format(countNoDisease/(len(df.HeartDisease))*100))
print("Percentage of Patients Have Disease : {:2f} %".format(countDisease/(len(df.HeartDisease))*100))

sns.countplot(x='Sex', data=df, palette='mako_r')
plt.xlabel("Sex (0 = female, 1=male)")
plt.show()

countFemale = len(df[df.Sex == 'F'])
countMale = len(df[df.Sex == 'M'])
print("Percentage of Female Patients: {:.2f} %".format((countFemale/(len(df.Sex))*100)))
print("Percentage of Male Patients: {:.2f} %".format((countMale/(len(df.Sex))*100)))

df.groupby('HeartDisease').mean(numeric_only=True)

df['Sex'].value_counts().plot.pie()

pd.crosstab(df.Age,df.HeartDisease).plot(kind="bar",figsize=(20,6))
plt.title('Heart Disease Frequency for Ages')
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.savefig('heartDiseaseAndAges.png')
plt.show()

pd.crosstab(df.Sex,df.HeartDisease).plot(kind="bar",figsize=(15,6),color=['#1CA53B','#AA1111'])
plt.title('Heart Disease Frequency for Sex')
plt.xlabel('Sex (F = Female, M = Male)')
plt.xticks(rotation=0)
plt.legend(["Haven't Disease", "Have Disease"])
plt.ylabel('Frequency')
plt.show()

plt.scatter(x=df.Age[df.HeartDisease==1], y=df.MaxHR[(df.HeartDisease==1)], c="red")
plt.scatter(x=df.Age[df.HeartDisease==0], y=df.MaxHR[(df.HeartDisease==0)])
plt.legend(["Disease", "Not Disease"])
plt.xlabel("Age")
plt.ylabel("Maximum Heart Rate")
plt.show()

df['Cholesterol'].plot(kind="box")

df.boxplot(column='Age', by='Sex')

#Transformation for dummy variables:
a = pd.get_dummies(df['Cholesterol'], prefix= "cp")
b = pd.get_dummies(df['Sex'], prefix ="thal")
c = pd.get_dummies(df['RestingECG'], prefix="slope")
d = pd.get_dummies(df['ExerciseAngina'], prefix="slope")
e = pd.get_dummies(df['ST_Slope'], prefix="slope")

frames= [df,a,b,c,d,e]
dfDummy = pd.concat(frames,axis=1)
dfDummy.head()

#Delete the categorial variables:
dfDummy.drop(columns=['ChestPainType','Sex','RestingECG','ExerciseAngina','ST_Slope'])

#Checking for double values:
x= df.shape[0]
df = df.drop_duplicates()
y=df.shape[0]

print("Avant l'operation:",x,"aprÃ©s l'operation:",y,'suppression',x-y,'doublons')

#Checking for missing values:
df.isnull()

df.isnull().sum()

#so we have a missing values so we have two choices :
#1: delete the missing values if they are little
#df1=df.dropna()
#df1.shape()
#df1.isnull().sum()
#2: imputing it
Age= df['Age']
Age_mean = Age.mean()
print(Age_mean)
df.Age.fillna(Age_mean, inplace=True)
df.isnull().sum()

df.Sex = df.Sex.fillna("Unknown")
print(df.isnull().sum())

df.to_csv('/content/CleanData.csv',index=False)

data = pd.read_csv("CleanData.csv")

data.head()

"""# **Encode the categorical features**"""

label_encoders = {}
categorical_features = ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']

# Encode each categorical feature
for feature in categorical_features:
    data[feature] = data[feature].astype(str)
    le = LabelEncoder()
    data.loc[:, feature] = le.fit_transform(data[feature])
    label_encoders[feature] = le


# Print the encoded data sample
print("Encoded Data Sample:")
print(data[categorical_features].head())

# Print the mapping for each feature
for feature in categorical_features:
    print(f"\nMapping for {feature}:")
    mapping = dict(zip(label_encoders[feature].classes_, label_encoders[feature].transform(label_encoders[feature].classes_)))
    print(mapping)

data.head()

"""# **Separate features and target**"""

x= data.drop(columns=['HeartDisease'])
y= data['HeartDisease']

"""# **Split the Data into training and test**"""

x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=42)

"""# **Standardize the numerical features**"""

scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.fit_transform(x_test)

"""# **The Model Neural Network**"""

# Define the model
model = Sequential([
    Dense(64, input_shape=(x_train.shape[1],), activation='relu'),
    Dropout(0.5),
    Dense(32, activation='relu'),
    Dropout(0.5),
    Dense(16, activation='relu'),
    Dense(1, activation='sigmoid')  # Output layer for binary classification
])

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(x_train, y_train, epochs=50, batch_size=32, validation_split=0.2)

# Evaluate the model
y_pred = (model.predict(x_test) > 0.5).astype(int)

# Print accuracy, classification report, and confusion matrix
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

joblib.dump(model,'heart_disease_model.pkl')
joblib.dump(label_encoders, 'label_encoders.pkl')

model_test = joblib.load('heart_disease_model.pkl')
label_encoders_test = joblib.load('label_encoders.pkl')

def encode_features(input_data, encoders):
    encoded_data = {}
    for feature, value in input_data.items():
        if feature in encoders:
            encoded_data[feature] = encoders[feature].transform([value])[0]
        else:
            encoded_data[feature] = value
    return encoded_data

# Example input data
input_data = {
    'Age': 63,
    'Sex': 'M',  # Original value
    'ChestPainType': 'ASY',  # Original value
    'RestingBP': 150,
    'Cholesterol': 223,
    'FastingBS': 0,
    'RestingECG': 'Normal',  # Original value
    'MaxHR': 115,
    'ExerciseAngina': 'N',  # Original value
    'Oldpeak': 0.0,
    'ST_Slope': 'Flat'  # Original value
}

# Encode the input data
encoded_input = encode_features(input_data, label_encoders_test)

# Convert encoded input data to a numpy array
features = np.array([list(encoded_input.values())])

# Standardize the features using the same scaler used during training
features = scaler.transform(features)

# Make a prediction
prediction_proba = model_test.predict(features)
prediction = (prediction_proba > 0.5).astype(int)  # Apply threshold to get class labels

print(f'Predicted class: {prediction[0][0]}')

